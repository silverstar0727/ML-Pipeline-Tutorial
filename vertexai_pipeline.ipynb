{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vertexai_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OWuiQ8ensT0"
      },
      "source": [
        "## 설치 및 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5a9ZFLANh98"
      },
      "source": [
        "# 해당 셀을 실행한 후에 반드시 \"런타임 다시시작\"을 해주세요\n",
        "!pip install -q kfp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4tXVkJumpXc"
      },
      "source": [
        "from typing import NamedTuple\n",
        "import json \n",
        "\n",
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
        "                        OutputPath, component, ClassificationMetrics)\n",
        "from kfp.v2.google.client import AIPlatformClient"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuGyYnmcnz4X"
      },
      "source": [
        "## GCP 연결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WimjuxN-BU1K"
      },
      "source": [
        "# gcp 연결\n",
        "from google.colab import auth as google_auth\n",
        "\n",
        "google_auth.authenticate_user()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlZSTwBSn1_j"
      },
      "source": [
        "# 환경변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO67PfIFNJo-"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "PROJECT_ID = 'mlops-210515'\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"gs://pipeline-129332\"\n",
        "\n",
        "USER = \"JeongMin-Do\"\n",
        "PIPELINE_ROOT = \"{}/pipeline_root/{}\".format(BUCKET_NAME, USER)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umWhS9W6n875"
      },
      "source": [
        "## Simple Sum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SCiq5bv3nb2F",
        "outputId": "02432e48-a545-486b-bd13-3a4a059fcff2"
      },
      "source": [
        "@component\n",
        "def sum_(a: int, b: int, c: int):\n",
        "    print(a + b + c)\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name = \"simple-sum\",\n",
        "    description = \"A simple sum pipeline\"\n",
        ")\n",
        "def sum_pipeline():\n",
        "    result1 = sum_(1, 0, 2)\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func = sum_pipeline, package_path = \"sum.json\"\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=\"sum.json\", pipeline_root=PIPELINE_ROOT\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/simple-sum-20210528061645?project=mlops-210515\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0zPSOseoAEf"
      },
      "source": [
        "## Hello World (I/O)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFGz4UK9FMab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be37e02c-02a2-45ea-822a-b9bd078c3b99"
      },
      "source": [
        "@component(output_component_file=\"hw.yaml\", base_image=\"python:3.9\")\n",
        "def hello_world(text: str) -> str:\n",
        "    print(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "@component(packages_to_install=[\"google-cloud-storage\"])\n",
        "def two_outputs(text: str) -> NamedTuple(\"Outputs\", [(\"output_one\", str), (\"output_two\", str)]):\n",
        "    from google.cloud import storage\n",
        "\n",
        "    o1 = f\"output one from text: {text}\"\n",
        "    o2 = f\"output two from text: {text}\"\n",
        "    print(\"output one: {}; output_two: {}\".format(o1, o2))\n",
        "    return (o1, o2)\n",
        "\n",
        "\n",
        "@component\n",
        "def consumer(text1: str, text2: str, text3: str):\n",
        "    print(f\"text1: {text1}; text2: {text2}; text3: {text3}\")\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"hello-world-v2\",\n",
        "    description=\"A simple intro pipeline\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "def intro_pipeline(text: str = \"hi there\"):\n",
        "    hw_task = hello_world(text)\n",
        "    two_outputs_task = two_outputs(text)\n",
        "    consumer_task = consumer( \n",
        "        hw_task.output,\n",
        "        two_outputs_task.outputs[\"output_one\"],\n",
        "        two_outputs_task.outputs[\"output_two\"],\n",
        "    )\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func=intro_pipeline, package_path=\"hw_pipeline_job.json\"\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=\"hw_pipeline_job.json\",\n",
        "    pipeline_root=PIPELINE_ROOT  # this argument is necessary if you did not specify PIPELINE_ROOT as part of the pipeline definition.\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/hello-world-v2-20210528061434?project=mlops-210515\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wk7TrfEXgmi-",
        "outputId": "73ca7b00-0303-43b5-f1cb-6f9bed7323e0"
      },
      "source": [
        "@component\n",
        "def args_generator_op() -> str:\n",
        "    import json\n",
        "\n",
        "    return json.dumps(\n",
        "        [{\"cats\": \"1\", \"dogs\": \"2\"}, {\"cats\": \"10\", \"dogs\": \"20\"}],\n",
        "        sort_keys=True,\n",
        "    )\n",
        "\n",
        "\n",
        "@component\n",
        "def print_op(msg: str):\n",
        "    print(msg)\n",
        "\n",
        "\n",
        "@component\n",
        "def flip_coin_op() -> str:\n",
        "    \"\"\"Flip a coin and output heads or tails randomly.\"\"\"\n",
        "    import random\n",
        "\n",
        "    result = \"heads\" if random.randint(0, 1) == 0 else \"tails\"\n",
        "    return result\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"flipcoin\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "def my_pipeline(\n",
        "    json_string: str = json.dumps(\n",
        "        [\n",
        "            {\n",
        "                \"snakes\": \"anaconda\",\n",
        "                \"lizards\": \"anole\",\n",
        "                \"bunnies\": [{\"cottontail\": \"bugs\"}, {\"cottontail\": \"thumper\"}],\n",
        "            },\n",
        "            {\n",
        "                \"snakes\": \"cobra\",\n",
        "                \"lizards\": \"gecko\",\n",
        "                \"bunnies\": [{\"cottontail\": \"roger\"}],\n",
        "            },\n",
        "            {\n",
        "                \"snakes\": \"boa\",\n",
        "                \"lizards\": \"iguana\",\n",
        "                \"bunnies\": [\n",
        "                    {\"cottontail\": \"fluffy\"},\n",
        "                    {\"fuzzy_lop\": \"petunia\", \"cottontail\": \"peter\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        sort_keys=True,\n",
        "    )\n",
        "):\n",
        "\n",
        "    flip1 = flip_coin_op()\n",
        "\n",
        "    with dsl.Condition(\n",
        "        flip1.output != \"no-such-result\", name=\"alwaystrue\"\n",
        "    ):  # always true\n",
        "\n",
        "        args_generator = args_generator_op()\n",
        "        with dsl.ParallelFor(args_generator.output) as item:\n",
        "            print_op(json_string)\n",
        "\n",
        "            with dsl.Condition(flip1.output == \"heads\", name=\"heads\"):\n",
        "                print_op(item.cats)\n",
        "\n",
        "            with dsl.Condition(flip1.output == \"tails\", name=\"tails\"):\n",
        "                print_op(item.dogs)\n",
        "\n",
        "    with dsl.ParallelFor(json_string) as item:\n",
        "        with dsl.Condition(item.snakes == \"boa\", name=\"snakes\"):\n",
        "            print_op(item.snakes)\n",
        "            print_op(item.lizards)\n",
        "            print_op(item.bunnies)\n",
        "\n",
        "    # it is possible to access sub-items\n",
        "    with dsl.ParallelFor(json_string) as item:\n",
        "        with dsl.ParallelFor(item.bunnies) as item_bunnies:\n",
        "            print_op(item_bunnies.cottontail)\n",
        "\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func = my_pipeline, package_path = \"flipcoin.json\"\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=\"flipcoin.json\", pipeline_root=PIPELINE_ROOT\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/flipcoin-20210528061435?project=mlops-210515\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "JqXbuZHIg2PY",
        "outputId": "6ef16307-8e53-4e3f-a785-c1a98f9916d3"
      },
      "source": [
        "@component(\n",
        "    packages_to_install=[\"sklearn\"],\n",
        "    base_image=\"python:3.9\",\n",
        "    output_component_file=\"wine_classif_component.yaml\",\n",
        ")\n",
        "def wine_classification(wmetrics: Output[ClassificationMetrics]):\n",
        "    from sklearn.datasets import load_wine\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import roc_curve\n",
        "    from sklearn.model_selection import cross_val_predict, train_test_split\n",
        "\n",
        "    X, y = load_wine(return_X_y=True)\n",
        "    # Binary classification problem for label 1.\n",
        "    y = y == 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "    rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    rfc.fit(X_train, y_train)\n",
        "    y_scores = cross_val_predict(rfc, X_train, y_train, cv=3, method=\"predict_proba\")\n",
        "    fpr, tpr, thresholds = roc_curve(\n",
        "        y_true=y_train, y_score=y_scores[:, 1], pos_label=True\n",
        "    )\n",
        "    wmetrics.log_roc_curve(fpr, tpr, thresholds)\n",
        "\n",
        "@component(packages_to_install=[\"sklearn\"], base_image=\"python:3.9\")\n",
        "def iris_sgdclassifier(\n",
        "    test_samples_fraction: float,\n",
        "    metricsc: Output[ClassificationMetrics],\n",
        "):\n",
        "    from sklearn import datasets, model_selection\n",
        "    from sklearn.linear_model import SGDClassifier\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    iris_dataset = datasets.load_iris()\n",
        "    train_x, test_x, train_y, test_y = model_selection.train_test_split(\n",
        "        iris_dataset[\"data\"],\n",
        "        iris_dataset[\"target\"],\n",
        "        test_size=test_samples_fraction,\n",
        "    )\n",
        "\n",
        "    classifier = SGDClassifier()\n",
        "    classifier.fit(train_x, train_y)\n",
        "    predictions = model_selection.cross_val_predict(classifier, train_x, train_y, cv=3)\n",
        "    metricsc.log_confusion_matrix(\n",
        "        [\"Setosa\", \"Versicolour\", \"Virginica\"],\n",
        "        confusion_matrix(\n",
        "            train_y, predictions\n",
        "        ).tolist(),  # .tolist() to convert np array to list.\n",
        "    )\n",
        "\n",
        "@component(\n",
        "    packages_to_install=[\"sklearn\"],\n",
        "    base_image=\"python:3.9\",\n",
        ")\n",
        "def iris_logregression(\n",
        "    input_seed: int,\n",
        "    split_count: int,\n",
        "    metrics: Output[Metrics],\n",
        "):\n",
        "    from sklearn import datasets, model_selection\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "    # Load digits dataset\n",
        "    iris = datasets.load_iris()\n",
        "    # # Create feature matrix\n",
        "    X = iris.data\n",
        "    # Create target vector\n",
        "    y = iris.target\n",
        "    # test size\n",
        "    test_size = 0.20\n",
        "\n",
        "    # cross-validation settings\n",
        "    kfold = model_selection.KFold(\n",
        "        n_splits=split_count, random_state=input_seed, shuffle=True\n",
        "    )\n",
        "    # Model instance\n",
        "    model = LogisticRegression()\n",
        "    scoring = \"accuracy\"\n",
        "    results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
        "    print(f\"results: {results}\")\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "        X, y, test_size=test_size, random_state=input_seed\n",
        "    )\n",
        "    # fit model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # accuracy on test set\n",
        "    result = model.score(X_test, y_test)\n",
        "    print(f\"result: {result}\")\n",
        "    metrics.log_metric(\"accuracy\", (result * 100.0))\n",
        "\n",
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        "    # A name for the pipeline.\n",
        "    name=\"metricspipelinev2\",\n",
        ")\n",
        "def pipeline(seed: int, splits: int):\n",
        "    wine_classification_op = wine_classification()  # noqa: F841\n",
        "    iris_logregression_op = iris_logregression(  # noqa: F841\n",
        "        input_seed=seed, split_count=splits\n",
        "    )\n",
        "    iris_sgdclassifier_op = iris_sgdclassifier(test_samples_fraction=0.3)  # noqa: F841\n",
        "\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func = pipeline, package_path = \"sklearn.json\"\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=\"sklearn.json\", pipeline_root=PIPELINE_ROOT, parameter_values={\"seed\": 5, \"splits\": 7},\n",
        ")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "pipeline_df = aiplatform.get_pipeline_df(pipeline=\"metrics-pipeline-v2\")\n",
        "\n",
        "df = pd.DataFrame(pipeline_df[\"metric.confidenceMetrics\"][0])\n",
        "auc = np.trapz(df[\"recall\"], df[\"falsePositiveRate\"])\n",
        "plt.plot(df[\"falsePositiveRate\"], df[\"recall\"], label=\"auc=\" + str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/metricspipelinev2-20210528061436?project=mlops-210515\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\npipeline_df = aiplatform.get_pipeline_df(pipeline=\"metrics-pipeline-v2\")\\n\\ndf = pd.DataFrame(pipeline_df[\"metric.confidenceMetrics\"][0])\\nauc = np.trapz(df[\"recall\"], df[\"falsePositiveRate\"])\\nplt.plot(df[\"falsePositiveRate\"], df[\"recall\"], label=\"auc=\" + str(auc))\\nplt.legend(loc=4)\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sZWVDkJ9hyEf",
        "outputId": "c1b0d97a-3366-498a-a30f-4b60df9e0ffd"
      },
      "source": [
        "@component\n",
        "def preprocess(\n",
        "    # An input parameter of type string.\n",
        "    message: str,\n",
        "    # Use Output to get a metadata-rich handle to the output artifact\n",
        "    # of type `Dataset`.\n",
        "    output_dataset_one: Output[Dataset],\n",
        "    # A locally accessible filepath for another output artifact of type\n",
        "    # `Dataset`.\n",
        "    output_dataset_two_path: OutputPath(\"Dataset\"),\n",
        "    # A locally accessible filepath for an output parameter of type string.\n",
        "    output_parameter_path: OutputPath(str),\n",
        "):\n",
        "    \"\"\"'Mock' preprocessing step.\n",
        "    Writes out the passed in message to the output \"Dataset\"s and the output message.\n",
        "    \"\"\"\n",
        "    output_dataset_one.metadata[\"hello\"] = \"there\"\n",
        "    # Use OutputArtifact.path to access a local file path for writing.\n",
        "    # One can also use OutputArtifact.uri to access the actual URI file path.\n",
        "    with open(output_dataset_one.path, \"w\") as f:\n",
        "        f.write(message)\n",
        "\n",
        "    # OutputPath is used to just pass the local file path of the output artifact\n",
        "    # to the function.\n",
        "    with open(output_dataset_two_path, \"w\") as f:\n",
        "        f.write(message)\n",
        "\n",
        "    with open(output_parameter_path, \"w\") as f:\n",
        "        f.write(message)\n",
        "\n",
        "\n",
        "@component(\n",
        "    base_image=\"python:3.9\",  # Use a different base image.\n",
        ")\n",
        "def train(\n",
        "    # An input parameter of type string.\n",
        "    message: str,\n",
        "    # Use InputPath to get a locally accessible path for the input artifact\n",
        "    # of type `Dataset`.\n",
        "    dataset_one_path: InputPath(\"Dataset\"),\n",
        "    # Use InputArtifact to get a metadata-rich handle to the input artifact\n",
        "    # of type `Dataset`.\n",
        "    dataset_two: Input[Dataset],\n",
        "    # Output artifact of type Model.\n",
        "    imported_dataset: Input[Dataset],\n",
        "    model: Output[Model],\n",
        "    # An input parameter of type int with a default value.\n",
        "    num_steps: int = 3,\n",
        "    # Use NamedTuple to return either artifacts or parameters.\n",
        "    # When returning artifacts like this, return the contents of\n",
        "    # the artifact. The assumption here is that this return value\n",
        "    # fits in memory.\n",
        ") -> NamedTuple(\n",
        "    \"Outputs\",\n",
        "    [\n",
        "        (\"output_message\", str),  # Return parameter.\n",
        "        (\"generic_artifact\", Artifact),  # Return generic Artifact.\n",
        "    ],\n",
        "):\n",
        "    \"\"\"'Mock' Training step.\n",
        "    Combines the contents of dataset_one and dataset_two into the\n",
        "    output Model.\n",
        "    Constructs a new output_message consisting of message repeated num_steps times.\n",
        "    \"\"\"\n",
        "\n",
        "    # Directly access the passed in GCS URI as a local file (uses GCSFuse).\n",
        "    with open(dataset_one_path, \"r\") as input_file:\n",
        "        dataset_one_contents = input_file.read()\n",
        "\n",
        "    # dataset_two is an Artifact handle. Use dataset_two.path to get a\n",
        "    # local file path (uses GCSFuse).\n",
        "    # Alternately, use dataset_two.uri to access the GCS URI directly.\n",
        "    with open(dataset_two.path, \"r\") as input_file:\n",
        "        dataset_two_contents = input_file.read()\n",
        "\n",
        "    with open(model.path, \"w\") as f:\n",
        "        f.write(\"My Model\")\n",
        "\n",
        "    with open(imported_dataset.path, \"r\") as f:\n",
        "        data = f.read()\n",
        "    print(\"Imported Dataset:\", data)\n",
        "\n",
        "    # Use model.get() to get a Model artifact, which has a .metadata dictionary\n",
        "    # to store arbitrary metadata for the output artifact. This metadata will be\n",
        "    # recorded in Managed Metadata and can be queried later. It will also show up\n",
        "    # in the UI.\n",
        "    model.metadata[\"accuracy\"] = 0.9\n",
        "    model.metadata[\"framework\"] = \"Tensorflow\"\n",
        "    model.metadata[\"time_to_train_in_seconds\"] = 257\n",
        "\n",
        "    artifact_contents = \"{}\\n{}\".format(dataset_one_contents, dataset_two_contents)\n",
        "    output_message = \" \".join([message for _ in range(num_steps)])\n",
        "    return (output_message, artifact_contents)\n",
        "\n",
        "@component\n",
        "def read_artifact_input(\n",
        "    generic: Input[Artifact],\n",
        "):\n",
        "    with open(generic.path, \"r\") as input_file:\n",
        "        generic_contents = input_file.read()\n",
        "        print(f\"generic contents: {generic_contents}\")\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name=\"metadata-pipeline-v2\",\n",
        ")\n",
        "def pipeline(message: str):\n",
        "    importer = kfp.dsl.importer(\n",
        "        artifact_uri=\"gs://ml-pipeline-playground/shakespeare1.txt\",\n",
        "        artifact_class=Dataset,\n",
        "        reimport=False,\n",
        "    )\n",
        "    preprocess_task = preprocess(message=message)\n",
        "    train_task = train(\n",
        "        dataset_one=preprocess_task.outputs[\"output_dataset_one\"],\n",
        "        dataset_two=preprocess_task.outputs[\"output_dataset_two\"],\n",
        "        imported_dataset=importer.output,\n",
        "        message=preprocess_task.outputs[\"output_parameter\"],\n",
        "        num_steps=5,\n",
        "    )\n",
        "    read_task = read_artifact_input(  # noqa: F841\n",
        "        train_task.outputs[\"generic_artifact\"]\n",
        "    )\n",
        "\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func = pipeline, package_path = \"sklearn.json\"\n",
        ")\n",
        "\n",
        "api_client = AIPlatformClient(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        ")\n",
        "\n",
        "response = api_client.create_run_from_job_spec(\n",
        "    job_spec_path=\"sklearn.json\", pipeline_root=PIPELINE_ROOT, parameter_values={\"message\": \"Hello, World\"},\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/metadata-pipeline-v2-20210528061437?project=mlops-210515\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXe_WUJwjJ6L"
      },
      "source": [
        ""
      ],
      "execution_count": 56,
      "outputs": []
    }
  ]
}