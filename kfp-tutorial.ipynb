{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a5c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /home/jupyter/.local/include/python3.7m/UNKNOWN\n",
      "sysconfig: /home/jupyter/.local/include/python3.7\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /home/jupyter/.local/include/python3.7m/UNKNOWN\n",
      "sysconfig: /home/jupyter/.local/include/python3.7\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /home/jupyter/.local/include/python3.7m/UNKNOWN\n",
      "sysconfig: /home/jupyter/.local/include/python3.7\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = True\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pip --upgrade --quiet --user\n",
    "!python3 -m pip install kfp --upgrade --quiet --user\n",
    "!python3 -m pip install tfx==0.27.0 --quiet --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d55559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e637a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/opt/conda/lib/python3.7/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dd4384eb9c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_model_analysis/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# See b/148667210 for why the ImportError is ignored.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtfma_unit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_eval_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttributionsForSlice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_model_analysis/api/tfma_unit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_eval_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_saved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_model_analysis/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfx_bsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0m_main_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorflow/core/kernels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0m_ll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# Load third party dynamic kernels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(library_location)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_libraries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /opt/conda/lib/python3.7/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Text\n",
    "\n",
    "import kfp\n",
    "\n",
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "from tfx.components import Evaluator\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.orchestration import data_types\n",
    "from tfx.orchestration import pipeline\n",
    "from tfx.orchestration.kubeflow import kubeflow_dag_runner\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.utils.dsl_utils import external_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In TFX MLMD schema, pipeline name is used as the unique id of each pipeline.\n",
    "# Assigning workflow ID as part of pipeline name allows the user to bypass\n",
    "# some schema checks which are redundant for experimental pipelines.\n",
    "pipeline_name = 'taxi_pipeline_with_parameters'\n",
    "\n",
    "# Path of pipeline data root, should be a GCS path.\n",
    "# Note that when running on KFP, the pipeline root is always a runtime parameter.\n",
    "# The value specified here will be its default.\n",
    "pipeline_root = os.path.join('gs://{{kfp-default-bucket}}', 'tfx_taxi_simple',\n",
    "                              kfp.dsl.RUN_ID_PLACEHOLDER)\n",
    "\n",
    "# Location of input data, should be a GCS path under which there is a csv file.\n",
    "data_root_param = data_types.RuntimeParameter(\n",
    "    name='data-root',\n",
    "    default='gs://ml-pipeline-playground/tfx_taxi_simple/data',\n",
    "    ptype=Text,\n",
    ")\n",
    "\n",
    "# Path to the module file, GCS path.\n",
    "# Module file is one of the recommended way to provide customized logic for component\n",
    "# includeing Trainer and Transformer.\n",
    "# See https://github.com/tensorflow/tfx/blob/93ea0b4eda5a6000a07a1e93d93a26441094b6f5/tfx/components/trainer/component.py#L38\n",
    "taxi_module_file_param = data_types.RuntimeParameter(\n",
    "    name='module-file',\n",
    "    default='gs://ml-pipeline-playground/tfx_taxi_simple/modules/taxi_utils.py',\n",
    "    ptype=Text,\n",
    ")\n",
    "\n",
    "# Number of epochs in training.\n",
    "train_steps = data_types.RuntimeParameter(\n",
    "    name='train-steps',\n",
    "    default=10,\n",
    "    ptype=int,\n",
    ")\n",
    "\n",
    "# Number of epochs in evaluation.\n",
    "eval_steps = data_types.RuntimeParameter(\n",
    "    name='eval-steps',\n",
    "    default=5,\n",
    "    ptype=int,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data location is parameterized by _data_root_param\n",
    "examples = external_input(data_root_param)\n",
    "example_gen = CsvExampleGen(input=examples)\n",
    "\n",
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "infer_schema = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'], infer_feature_shape=False)\n",
    "\n",
    "validate_stats = ExampleValidator(\n",
    "  statistics=statistics_gen.outputs['statistics'],\n",
    "  schema=infer_schema.outputs['schema'])\n",
    "\n",
    "# The module file used in Transform and Trainer component is paramterized by\n",
    "# _taxi_module_file_param.\n",
    "transform = Transform(\n",
    "  examples=example_gen.outputs['examples'],\n",
    "  schema=infer_schema.outputs['schema'],\n",
    "  module_file=taxi_module_file_param)\n",
    "\n",
    "# The numbers of steps in train_args are specified as RuntimeParameter with\n",
    "# name 'train-steps' and 'eval-steps', respectively.\n",
    "trainer = Trainer(\n",
    "  module_file=taxi_module_file_param,\n",
    "  transformed_examples=transform.outputs['transformed_examples'],\n",
    "  schema=infer_schema.outputs['schema'],\n",
    "  transform_graph=transform.outputs['transform_graph'],\n",
    "  train_args={'num_steps': train_steps},\n",
    "  eval_args={'num_steps': eval_steps})\n",
    "\n",
    "# Set the TFMA config for Model Evaluation and Validation.\n",
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[\n",
    "      # Using signature 'eval' implies the use of an EvalSavedModel. To use\n",
    "      # a serving model remove the signature to defaults to 'serving_default'\n",
    "      # and add a label_key.\n",
    "      tfma.ModelSpec(signature_name='eval')\n",
    "    ],\n",
    "    metrics_specs=[\n",
    "      tfma.MetricsSpec(\n",
    "          # The metrics added here are in addition to those saved with the\n",
    "          # model (assuming either a keras model or EvalSavedModel is used).\n",
    "          # Any metrics added into the saved model (for example using\n",
    "          # model.compile(..., metrics=[...]), etc) will be computed\n",
    "          # automatically.\n",
    "          metrics=[\n",
    "              tfma.MetricConfig(class_name='ExampleCount')\n",
    "          ],\n",
    "          # To add validation thresholds for metrics saved with the model,\n",
    "          # add them keyed by metric name to the thresholds map.\n",
    "          thresholds = {\n",
    "              'binary_accuracy': tfma.MetricThreshold(\n",
    "                  value_threshold=tfma.GenericValueThreshold(\n",
    "                      lower_bound={'value': 0.5}),\n",
    "                  change_threshold=tfma.GenericChangeThreshold(\n",
    "                     direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                     absolute={'value': -1e-10}))\n",
    "          }\n",
    "      )\n",
    "    ],\n",
    "    slicing_specs=[\n",
    "      # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
    "      tfma.SlicingSpec(),\n",
    "      # Data can be sliced along a feature column. In this case, data is\n",
    "      # sliced along feature column trip_start_hour.\n",
    "      tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
    "    ])\n",
    "\n",
    "# The name of slicing column is specified as a RuntimeParameter.\n",
    "evaluator = Evaluator(\n",
    "  examples=example_gen.outputs['examples'],\n",
    "  model=trainer.outputs['model'],\n",
    "  eval_config=eval_config)\n",
    "\n",
    "pusher = Pusher(\n",
    "  model=trainer.outputs['model'],\n",
    "  model_blessing=evaluator.outputs['blessing'],\n",
    "  push_destination=pusher_pb2.PushDestination(\n",
    "      filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "          base_directory=os.path.join(\n",
    "              str(pipeline.ROOT_PARAMETER), 'model_serving'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DSL pipeline object.\n",
    "# This pipeline obj carries the business logic of the pipeline, but no runner-specific information\n",
    "# was included.\n",
    "dsl_pipeline = pipeline.Pipeline(\n",
    "  pipeline_name=pipeline_name,\n",
    "  pipeline_root=pipeline_root,\n",
    "  components=[\n",
    "      example_gen, statistics_gen, infer_schema, validate_stats, transform,\n",
    "      trainer, model_analyzer, model_validator, pusher\n",
    "  ],\n",
    "  enable_cache=True,\n",
    "  beam_pipeline_args=['--direct_num_workers=%d' % 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a TFX docker image. For the full list of tags please see:\n",
    "# https://hub.docker.com/r/tensorflow/tfx/tags\n",
    "tfx_image = 'gcr.io/tfx-oss-public/tfx:0.27.0'\n",
    "config = kubeflow_dag_runner.KubeflowDagRunnerConfig(\n",
    "      kubeflow_metadata_config=kubeflow_dag_runner\n",
    "      .get_default_kubeflow_metadata_config(),\n",
    "      tfx_image=tfx_image)\n",
    "kfp_runner = kubeflow_dag_runner.KubeflowDagRunner(config=config)\n",
    "# KubeflowDagRunner compiles the DSL pipeline object into KFP pipeline package.\n",
    "# By default it is named <pipeline_name>.tar.gz\n",
    "kfp_runner.run(dsl_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46503ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_result = kfp.Client(\n",
    "    host='1234567abcde-dot-us-central2.pipelines.googleusercontent.com'  # Put your KFP endpoint here\n",
    ").create_run_from_pipeline_package(\n",
    "    pipeline_name + '.tar.gz', \n",
    "    arguments={\n",
    "        # Uncomment following lines in order to use custom GCS bucket/module file/training data.\n",
    "        # 'pipeline-root': 'gs://<your-gcs-bucket>/tfx_taxi_simple/' + kfp.dsl.RUN_ID_PLACEHOLDER,\n",
    "        # 'module-file': '<gcs path to the module file>',  # delete this line to use default module file.\n",
    "        # 'data-root': '<gcs path to the data>'  # delete this line to use default data.\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
